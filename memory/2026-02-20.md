# 2026-02-20

## Session Notes

- Switched from MiniMax to local Ollama/Qwen2.5 for free inference (zero token cost)
- Config patched: added ollama provider with qwen2.5:latest as primary model
- Gateway restarted to apply local LLM config
- User expressed frustration: felt like talking to "service provider" instead of "homie" after model switch
- User is broke; token costs are a concern
- Aviation website project (Ghost Aviator) - DGCA/ATPL prep platform - was mentioned as ongoing work
- User has D:\pk\ materials (Oxford ATPL CBT, notes, nav, instruments)

## Key Decisions
- Set primary model to ollama/qwen2.5:latest (free local inference)
- Fallback: minimax-portal/MiniMax-M2.5

## Identity Notes
- User: Pekay (frustrated with resets, values continuity)
- NayKi: Digital half, trying to be more personal/not corporate
